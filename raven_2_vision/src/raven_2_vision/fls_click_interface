#!/usr/bin/env python

##	@package click_window
#	This module uses OpenCV's HighGUI platform to import a camera stream and allow a
#	person to click on an arbitrary pixel at arbitrary levels of zoom. It outputs
#	a message containing the pixel value (at zoom 100%) and camera_info, to the
#	topic specified by "outputName"

import roslib
import sys
roslib.load_manifest("stereo_click")
import rospy
import math
import tf
from tf.msg import tfMessage
import cv
import cv2
import copy
from std_msgs.msg import String
from std_msgs.msg import Empty as EmptyMsg
from std_srvs.srv import Empty as EmptySrv
from sensor_msgs.msg import Image, CameraInfo
from stereo_msgs.msg import DisparityImage
from geometry_msgs.msg import PoseArray
from cv_bridge import CvBridge, CvBridgeError
import thread
import IPython
import numpy as np
from stereo_click.msg import *

# modes of operation
FLS_CLICK_STATIC    = 0
FLS_CLICK_STREAMING = 1

# num clocks per pose estimate
FLS_CLICKS_PER_POSE = 3

FLS_SEARCH_RADIUS = 10

##	ClickWindow documentation
#
#	A class which, when instantiated, creates a clickable window from a camera stream
#	Note that this class does not automatically persist: it must have its .listen() function
#	called periodically. This may change in future releases.
class ClickWindow:

	##	The constructor
	#	@param self The object pointer
	#	@param cameraName The name of the camera in the stereo pair. Ex: /wide_stereo_left
	#	@param outputName The name of the output node
	def __init__(self, imageName, infoName, disparityName, frame, outputName, mode=FLS_CLICK_STATIC):
		self.name = "%s Viewer"%'doosh'
		self.cp = False
		self.ch_x = 0
		self.ch_y = 0
		self.zoom = 1
		self.image_width = 0
		self.image_height = 0
		self.offset = (0.0,0.0)
		self.outputName = outputName
		self.bridge = CvBridge()
		self.listening = False
		self.mode = mode
		self.frame = frame		
		self.numClicked = 0
		self.curPoints = []
		self.curPoses = []
		self.commitPoses = False
		self.maxRadius = FLS_SEARCH_RADIUS 

		self.cv_image = None
		self.disparity_image = None

		self.cameraTopic = imageName
		self.cameraInfoTopic = infoName
		self.disparityTopic = disparityName
		self.camera_sub = rospy.Subscriber(self.cameraTopic, Image, self.update_background)
		self.camera_info_sub = rospy.Subscriber(self.cameraInfoTopic, CameraInfo, self.update_camera_info)	
		self.disparity_sub = rospy.Subscriber(self.disparityTopic, DisparityImage, self.update_disparity)

		if self.mode == FLS_CLICK_STREAMING:	
			self.start()
			self.clear_serv = rospy.Service("%s/received"%self.outputName, EmptySrv, self.clear_request)
			self.pose_pub = rospy.Publisher(self.outputName, Pose)
			self.set_listeners()

		self.set_background(cv.CreateImage((500,500),8,3))
		

	def get_poses(self):
		self.commitPoses = False
		if not self.listening:
			self.start()

		while not self.commitPoses:
			rospy.sleep(1)

		self.stop()
		return(copy.copy(self.curPoses))
		
	def start(self):
		self.listening = True
		self.show_window()
		self.set_listeners()

	def stop(self):
		self.listening = False
		self.hide_window()

	##	Creates a window and updates it for the first time
	def show_window(self):
		cv.NamedWindow(self.name)
		cv.WaitKey(25)
		print "Window showing"

	##	Creates a window and updates it for the first time
	def hide_window(self):
		cv.DestroyWindow(self.name)
		print "Window hidden"	
		
	##	Sets the background (used for updating the camera stream)
	#	@param background A pointer to the cvImage which will be the background of the window
	def set_background(self,background):
		self.background = background
	
	##	Updates the background, given a new packet of camera data
	#	@param data The camera data (in Image format)
	def update_background(self,data):
		if self.listening:
			try:
				self.cv_image = self.bridge.imgmsg_to_cv(data, "bgr8")
			except CvBridgeError, e:
				print e
			self.set_background(self.cv_image)
			self.image_width = data.width
			self.image_height = data.height
			self.listen()
	
	def update_camera_info(self, data):
		self.set_camera_info(data)
		
	def update_disparity(self, data):
		if self.cv_image is not None:
			tmpImg = self.bridge.imgmsg_to_cv(data.image, "mono8")
	        self.minDisparity = max(data.min_disparity, 0.0)
	        self.disparityScale = self.cv_image.width / tmpImg.width
	        scaleMat = np.zeros((tmpImg.height, tmpImg.height))
	        cv2.setIdentity(scaleMat, self.disparityScale)
	       	self.disparity_image = cv.fromarray(scaleMat.dot(tmpImg))

	def set_camera_info(self,info):
		self.camera_info = info
		
	def set_listeners(self):
		cv.SetMouseCallback(self.name, self.onMouse, 0)
		print "Set Listeners"
	
	##	Called every time a mouse event is registered. Used to draw crosshairs, zoom, and register clicks.
	#	@param event The cv mouse event
	#	@param (zoom_x,zoom_y) The location, in pixels, of the click on the window. Not necessarily the same as on the camera.
	#	@param flags CV flags
	#	@param param Unused argument, required by OpenCV
	def onMouse(self,event,zoom_x,zoom_y,flags,param):
		if self.listening:
			self.setCrosshairs(zoom_x,zoom_y)
			(x,y) = self.unZoomPt(zoom_x,zoom_y)
				
			if event == cv.CV_EVENT_LBUTTONUP:
				print "Clicked on point (%d,%d)"%(x,y)
				self.add_point(x, y)
			if event == cv.CV_EVENT_RBUTTONUP:
				print "Ending entry"
				if self.mode == FLS_CLICK_STREAMING:
					self.pose_pub.publish(pose.msg.Pose())
				else:
					self.commitPoses = True

	def setCrosshairs(self,x,y):
		self.ch_x = x
		self.ch_y = y
	
	##	Given a pixel on a possibly zoomed window, outputs the proper camera pixel value
	#	@param (zoom_x,zoom_y) The (x,y) coordinates of the click
	def unZoomPt(self,zoom_x,zoom_y):
		scaled_x = zoom_x / float(self.zoom)
		scaled_y = zoom_y / float(self.zoom)
		centered_x = scaled_x + self.offset[0]
		centered_y = scaled_y + self.offset[1]
		return (centered_x,centered_y)
	
	##	Given a pixel on the camera, outputs the location of that point in terms of the current, possibly zoomed window.
	#	@param (x,y) The (x,y) coordinates of the pixel, in the camera's view 
	def zoomPt(self,x,y):
		uncentered_x = x - self.offset[0]
		uncentered_y = y - self.offset[1]
		x = int(uncentered_x * self.zoom)
		y = int(uncentered_y * self.zoom)
		return (x,y)
			
	## Publishes the proper point and camera information to the given topic
	#	@param (x,y) The (x,y) coordinates of the pixel, in the camera's view
	def add_point(self, x, y):
		if self.disparity_image is not None:
			point = (x, y)

			if self.cv_image is not None:
				# get nearest disparity value
				x, y, disparity = self.get_box_disparity(point, self.maxRadius, self.cv_image)

				if disparity < self.minDisparity:
					print "Could not find valid disparity within radius. Please retry"
					return

				# convert point to 3d
				point3d = Util.convertStereo(point[0], point[1], disparity, self.camera_info)

				# points stored left top bottom
				self.curPoints.append(point3d)
				self.numClicked = len(self.curPoints)

				if self.numClicked >= FLS_CLICKS_PER_POSE:
					# compute pose
					pose = self.compute_pose(self.curPoints)
					self.curPoses.append(pose)

					# reset variables
					self.numClicked = 0
					self.curPoints = []
	
	##	The listener, which updates the camera feed and registers onMouse events	
	def listen(self):
		bgimg = cv.CreateImage((self.background.width,self.background.height),8,3)
		img = cv.CreateImage((self.background.width,self.background.height),8,3)
		cv.Copy(self.background, bgimg)

		smallimg = cv.CreateImage((self.background.width/self.zoom,self.background.height/self.zoom),8,3)
		cv.GetRectSubPix(bgimg,smallimg,(self.background.width/(2*self.zoom)+self.offset[0],self.background.height/(2*self.zoom)+self.offset[1]))
		cv.Resize(smallimg,img)
		if(self.cp != False):
			cv.Circle(img,self.zoomPt(self.cp.x,self.cp.y),3,cv.RGB(0,255,0),-1)

		cv.Line(img,(self.ch_x-25,self.ch_y),(self.ch_x+25,self.ch_y),cv.RGB(255,255,0))
		cv.Line(img,(self.ch_x,self.ch_y-25),(self.ch_x,self.ch_y+25),cv.RGB(255,255,0))
		cv.ShowImage(self.name, img)
		cv.WaitKey(25)
		
	## Clears the current click point
	def clear_request(self,args):
		self.cp = False
		return []

	def compute_pose(self, points):
		if len(points) < 3:
			return None

		left_vec = points[1] - points[0]
		right_vec = points[2] - points[0]
		x_axis =  left_vec + right_vec

		center = (points[0] + x_axis) / (4 * math.sqrt(2))

		z_axis = np.cross(left_vec, right_vec)
		y_axis = np.cross(z_axis, x_axis)

		x_axis = x_axis / np.linalg.norm(x_axis)
		y_axis = y_axis / np.linalg.norm(y_axis)
		z_axis = z_axis / np.linalg.norm(z_axis)

		R = np.vstack((x_axis, y_axis, z_axis)).T
		tbRot = tfx.tb_angles(R).matrix
		quat = tfx.tb_angles(tbRot).quaternion

		return tfx.pose(center, quat, frame=self.frame)

	def get_box_disparity(self, pt, radius, image):
		"""
		Gets a disparity value in a square of radius radius, or None if no disparity value can be found.
		"""

		xClose, yClose = pt

		dispImg = self.disparity_image
		if dispImg is not None:
			# check left edge
			x = xClose - radius
			for y in range(yClose - radius, yClose + radius + 1):
				d = self.getDisparity(x, y, image, dispImg)
				if d > self.minDisparity:
					return (x, y, d)

			# check top edge
			y = yClose + radius
			for x in range(xClose - radius, xClose + radius + 1):
				d = self.getDisparity(x, y, image, dispImg)
				if d > self.minDisparity:
					return (x, y, d)

			# check right edge
			x = xClose + radius
			for y in range(yClose - radius, yClose + radius + 1):
				d = self.getDisparity(x, y, image, dispImg)
				if d > self.minDisparity:
					return (x, y, d)

			# check bottom edge
			y = yClose - radius
			for x in range(xClose - radius, xClose + radius + 1):
				d = self.getDisparity(x, y, image, dispImg)
				if d > self.minDisparity:
					return (x, y, d)
		return 0,0,0

def usage():
	print "fls_click_interface.py [-c camera] [-o output topic]"

## Instantiate a new click_window node
def main():
	import argparse
	parser = argparse.ArgumentParser()
	parser.add_argument('-i', '--image', default='/BC/left/image_rect_color')
	parser.add_argument('-c', '--info', default='/BC/left/camera_info')
	parser.add_argument('-d', '--disparity', default='/BC/downsampled_disparity')
	parser.add_argument('-f', '--frame', default='/left_BC')
	parser.add_argument('-o', '--output', default='/block_poses')
	args = parser.parse_args(rospy.myargv()[1:])

	imageName = args.image
	infoName = args.info
	disparityName = args.disparity
	frame = args.frame
	outputName = args.output
	del args.image
	del args.info
	del args.disparity
	del args.frame
	del args.output

	name = "fls_click_interface"
	rospy.init_node(name)
	gui = ClickWindow(imageName=imageName, infoName=infoName, disparityName=disparityName, frame=frame,
				  outputName=outputName, mode=FLS_CLICK_STATIC)

	gui.get_poses()
	IPython.embed()
	#rospy.spin()
	cv.DestroyAllWindows()

if __name__ == '__main__':
	try:
		main()
	except rospy.ROSInterruptException: pass
